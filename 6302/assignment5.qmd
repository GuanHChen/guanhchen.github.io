---
title: "Methods of Data Collection and Production"
subtitle: "Assignment 5"
author: "Guan Chen"
date: last-modified
toc: false
title-block-banner: true
---

### YouTubenews01.R

```{r}
#| eval: false
## Collecting Social Media data: YouTube

# Required Libraries
# Install if necessary
# install.packages("tuber")
# install.packages("tidyverse")
# install.packages("lubridate")
# install.packages("stringi")
# install.packages("wordcloud")
# install.packages("gridExtra")
# install.packages("httr")
# install.packages("tm")

library(tuber)
library(tidyverse)
library(lubridate)
library(stringi)
library(wordcloud)
library(gridExtra)
library(httr)
library(tm)


### Step 1: Apply for the Google YouTube API


### 1.  Go to Google Cloud Console (https://cloud.google.com/).
### 2.  Create a new project or select an existing one.
### 3.  Search for and enable the YouTube Data API v3.
### 4.  Go to Credentials > Create Credentials > OAuth Client ID.
### 5.  Set up the OAuth consent screen
### 6.  Name the App (e.g. YouTube analyzer), enter support email
### 7.  Application type: web application
### 8.  Name: Web client 1
### 9.  Generate Client ID and Client Secret.

### Step 2: Authenticate with YouTube API

#### Use your Client ID and Client Secret to authenticate.

# Replace with your actual Client ID and Client Secret
yt_oauth("YourClientID", "YourClientSecret", token = "")

### Important:  when running for first time, you will be prompted to:
### 1. add the .httr-oauth to .gitignore, select 1 to consent. 
### 2. Then it will open browser to choose your Google account.  ### 3. When prompted with safety statement ("Google hasn’t verified this app"), click advanced and click Go to Appname (unsafe) to verify.  
### 4. When done, the message will show "Authentication complete. Please close this page and return to R."
### 5. Return to RStudio.  When seeing:
###  
### "Waiting for authentication in browser...
### Press Esc/Ctrl + C to abort
### Authentication complete.
### 
### It is ready to collect YouTube data


### Step 3: Download YouTube Data

#### Here’s an example of collecting data on the “US election 2024.”

#### Search for videos related to "US election 2024"
yt_uselection2024 <- yt_search(term = "US election 2024")


#### Display the first few rows

head(yt_uselection2024)


### Step 4: Basic Analytics on YouTube Data

#### Most Frequent Words in Video Titles

# Extract titles and clean up

# Extract titles and clean up
titles <- yt_uselection2024$title
titles_clean <- tolower(titles) %>%
  stri_replace_all_regex("[[:punct:]]", "") %>%
  str_split(" ") %>%
  unlist()

# Create a word frequency table
word_freq <- table(titles_clean)
word_freq_df <- as.data.frame(word_freq, stringsAsFactors = FALSE)
colnames(word_freq_df) <- c("word", "freq")

# Filter common words (stop words) and plot a word cloud
word_freq_df <- word_freq_df %>% filter(!word %in% tm::stopwords("en"))
set.seed(123)
wordcloud(words = word_freq_df$word, freq = word_freq_df$freq, max.words = 50)


### 4.2. Plot Video Publish Dates

# Format publish dates and aggregate data


yt_sm <- yt_uselection2024 %>%
  mutate(publish_date = as.Date(publishedAt)) %>%
  count(publish_date)

# Plot the frequency of videos published over time
ggplot(yt_sm, aes(x = publish_date, y = n)) +
  geom_line(color = "blue") +
  labs(title = "Videos Published Over Time", x = "Date", y = "Number of Videos") +  
  theme_bw()
###  4.3. Top Channels by Video Count


# Summarize by channel
top_channels <- yt_uselection2024 %>%
  count(channelTitle, sort = TRUE) %>%
  top_n(10)

# Plot top channels
ggplot(top_channels, aes(x = reorder(channelTitle, n), y = n)) +
  geom_bar(stat = "identity", fill = "red") +
  coord_flip() +
  labs(title = "Top Channels on 'US election 2024'", x = "Channel", y = "Number of Videos")
```

Yes, the YouTube comments is text data that can be analyzed by quanteda. The text must be cleaned and pre-processed, but there is likely information that can be mined from Youtube comment data.
